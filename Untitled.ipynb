{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3b1bd82-c1b0-4ea1-9a28-f4998b50d955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import torch\n",
    "import torchaudio\n",
    "import wave\n",
    "from distutils.dir_util import copy_tree\n",
    "from glob import glob\n",
    "from pyannote.audio import Pipeline\n",
    "from pydub import AudioSegment\n",
    "from speechbrain.pretrained import SpectralMaskEnhancement\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff262213-2ba2-49ca-b224-f601283e7b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='logs.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8f8da05-9575-4daa-aee3-1b49ff1ee3fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyannote.audio.pipelines.speaker_diarization.SpeakerDiarization at 0x7fb11910c100>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-3.1\",\n",
    "    use_auth_token=\"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\")\n",
    "pipeline.to(torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d43d33c-8333-4689-8598-aa14338a255c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 55/55 [03:48<00:00,  4.15s/it]\n"
     ]
    }
   ],
   "source": [
    "audio_paths = glob('./audio_raw/*')\n",
    "for audio_path in tqdm(audio_paths):\n",
    "    audio_name = audio_path.split('/')[-1]\n",
    "    audio_name_no_ext = audio_name.split('.')[0]\n",
    "    output_path = f'./wav_raw/{audio_name_no_ext}.wav'\n",
    "    ffmpeg_script = f'ffmpeg -i {audio_path} -vn -acodec pcm_s16le -ar 44100 -ac 2 {output_path} -y'\n",
    "    ffmpeg_output = subprocess.run(\n",
    "        ffmpeg_script, \n",
    "        shell=True, \n",
    "        check=True, \n",
    "        capture_output=True,\n",
    "        text=True)\n",
    "    logger.info(ffmpeg_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f71b622-5691-4184-b568-f430c5fe2c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 55/55 [01:52<00:00,  2.05s/it]\n"
     ]
    }
   ],
   "source": [
    "def get_wav_duration(file_path):\n",
    "    with wave.open(file_path, 'rb') as wav_file:\n",
    "        num_frames = wav_file.getnframes()\n",
    "        frame_rate = wav_file.getframerate()\n",
    "        duration = num_frames / float(frame_rate)\n",
    "        return duration\n",
    "\n",
    "\n",
    "wav_paths = glob('./wav_raw/*.wav')\n",
    "for wav_path in tqdm(wav_paths):\n",
    "    duration = get_wav_duration(wav_path)\n",
    "    wav_name = wav_path.split('/')[-1]\n",
    "    wav_name_no_ext = wav_name.split('.')[0]\n",
    "    if duration > 600:\n",
    "        segment_wav_path = f'./wav_10_minutes/{wav_name_no_ext}_%06d.wav'\n",
    "        ffmpeg_script = f'ffmpeg -i {wav_path} -f segment -segment_time 600 -c copy {segment_wav_path}'\n",
    "        ffmpeg_output = subprocess.run(\n",
    "            ffmpeg_script, \n",
    "            shell=True, \n",
    "            check=True, \n",
    "            capture_output=True,\n",
    "            text=True)\n",
    "        logger.info(ffmpeg_output)\n",
    "    else:\n",
    "        shutil.copy(wav_path, f'./wav_10_minutes/{wav_name_no_ext}.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6c49e52-bf2e-4f7c-867c-697d79f7cf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diarize_and_remove_overlap(segmented_wav_path):\n",
    "    diarization = pipeline(segmented_wav_path)\n",
    "    start_end_speakers_list = []\n",
    "    for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "        start_end = [turn.start, turn.end]\n",
    "        start_end_speakers_list.append([start_end, speaker])\n",
    "    start_end_speakers_list = sorted(start_end_speakers_list, key=lambda sublist: sublist[0][0])\n",
    "    start_end_speakers_list_no_overlap = []\n",
    "    compared_sublist = start_end_speakers_list[0]\n",
    "    for index in range(1, len(start_end_speakers_list)):\n",
    "        current_sublist = start_end_speakers_list[index]\n",
    "        if compared_sublist[0][1] > current_sublist[0][0]:\n",
    "            continue\n",
    "        start_end_speakers_list_no_overlap.append(current_sublist)\n",
    "        compared_sublist = current_sublist\n",
    "    logger.info(\n",
    "        f'Original diarized segments: {len(start_end_speakers_list)}'\n",
    "        f'Overlap removed: {len(start_end_speakers_list_no_overlap)}'\n",
    "    )\n",
    "    logger.info(f'Lost {1 - len(start_end_speakers_list_no_overlap) / (len(start_end_speakers_list)):.2f}%')\n",
    "    speaker_dict = {segmented_wav_path: {}}\n",
    "    for start_end, speaker in start_end_speakers_list_no_overlap:\n",
    "        if speaker not in speaker_dict[segmented_wav_path]:\n",
    "            speaker_dict[segmented_wav_path][speaker] = []\n",
    "        speaker_dict[segmented_wav_path][speaker].append(start_end)\n",
    "    return speaker_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d87d7df0-f136-4efc-9a56-22eb4fe6c20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 442/442 [18:52:43<00:00, 153.76s/it]\n"
     ]
    }
   ],
   "source": [
    "speaker_dict_list = []\n",
    "segmented_wav_paths = glob('./wav_10_minutes/*.wav')\n",
    "for segmented_wav_path in tqdm(segmented_wav_paths):\n",
    "    segmented_wav_name = segmented_wav_path.split('/')[-1]\n",
    "    segmented_wav_name_no_ext = segmented_wav_name.split('.')[0]\n",
    "    temp_speaker_dict = diarize_and_remove_overlap(segmented_wav_path)\n",
    "    speaker_dict_list.append(temp_speaker_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71c6e781-7712-4e4f-bfc7-e32f2e624405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# created diarized_results dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37d9c96e-455a-40d2-8df3-cc930aa95cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 442/442 [01:14<00:00,  5.96it/s]\n"
     ]
    }
   ],
   "source": [
    "for speaker_dict in tqdm(speaker_dict_list):\n",
    "    segmented_wav_name = list(speaker_dict.keys())[0].split('/')[-1]\n",
    "    segmented_wav_name_no_ext = segmented_wav_name.split('.')[0]\n",
    "    diarized_sub_dir_path = f'./diarized_results/{segmented_wav_name_no_ext}'\n",
    "    if not os.path.exists(diarized_sub_dir_path):\n",
    "        os.mkdir(diarized_sub_dir_path)\n",
    "    wav_source = AudioSegment.from_wav(list(speaker_dict.keys())[0])\n",
    "    for speaker in speaker_dict[list(speaker_dict.keys())[0]]:\n",
    "        speaker_path = f'{diarized_sub_dir_path}/{speaker}'\n",
    "        if not os.path.exists(speaker_path):\n",
    "            os.mkdir(speaker_path)\n",
    "        speaker_snippet_index = 0\n",
    "        for start_end in speaker_dict[list(speaker_dict.keys())[0]][speaker]:\n",
    "            t1 = start_end[0] * 1000\n",
    "            t2 = start_end[1] * 1000\n",
    "            if (t2 - t1) < 3000:\n",
    "                continue\n",
    "            wav_snippet = wav_source[t1: t2]\n",
    "            wav_snippet_path = f'{speaker_path}/{segmented_wav_name_no_ext}_{speaker_snippet_index}.wav'\n",
    "            wav_snippet.export(wav_snippet_path, format=\"wav\")\n",
    "            speaker_snippet_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2fde0d9a-36cd-4891-95b9-a88a5e8ee2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Why are enhanced results bad?\n",
    "# copied_paths = copy_tree('./diarized_results', './diarized_results_enhanced')\n",
    "# enhance_model = SpectralMaskEnhancement.from_hparams(\n",
    "#     source=\"speechbrain/metricgan-plus-voicebank\",\n",
    "#     savedir=\"./pretrained_models/metricgan-plus-voicebank\",\n",
    "# )\n",
    "\n",
    "# for copied_path in copied_paths:\n",
    "#     noisy = enhance_model.load_audio(copied_path).unsqueeze(0)\n",
    "#     enhanced = enhance_model.enhance_batch(noisy, lengths=torch.tensor([1.]))\n",
    "#     torchaudio.save(copied_path, enhanced.cpu(), 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7de7109-2804-49d7-954e-ab9dff90c453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wav_sample_rate(file_path):\n",
    "    with wave.open(file_path, 'rb') as wav_file:\n",
    "        frame_rate = wav_file.getframerate()\n",
    "        return frame_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a24a476d-9194-4458-99a1-54e4183c233d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17538"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diarized_results = glob('./diarized_results/*/*/*')\n",
    "len(diarized_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3965c6f-dd7f-4802-8e56-00eceb6dddc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([(44100, 17538)])\n"
     ]
    }
   ],
   "source": [
    "sample_rate_dict = {}\n",
    "for diarized_wav_path in diarized_results:\n",
    "    temp_sample_rate = get_wav_sample_rate(diarized_wav_path)\n",
    "    if temp_sample_rate not in sample_rate_dict:\n",
    "        sample_rate_dict[temp_sample_rate] = []\n",
    "    sample_rate_dict[temp_sample_rate].append(diarized_wav_path)\n",
    "sample_rate_count_dict = {}\n",
    "for sample_key in list(sample_rate_dict):\n",
    "    sample_rate_count_dict[sample_key] = len(sample_rate_dict[sample_key])\n",
    "sample_rate_count_dict = collections.OrderedDict(sorted(sample_rate_count_dict.items()))\n",
    "print(sample_rate_count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1f9f04-1481-4722-9d0a-c3bc29047c68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
