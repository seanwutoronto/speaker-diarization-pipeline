{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d3b1bd82-c1b0-4ea1-9a28-f4998b50d955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import torch\n",
    "import wave\n",
    "from glob import glob\n",
    "from pyannote.audio import Pipeline\n",
    "from pydub import AudioSegment\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ff262213-2ba2-49ca-b224-f601283e7b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='logs.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8f8da05-9575-4daa-aee3-1b49ff1ee3fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyannote.audio.pipelines.speaker_diarization.SpeakerDiarization at 0x7f5e0ced2b90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-3.1\",\n",
    "    use_auth_token=\"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\")\n",
    "pipeline.to(torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8d43d33c-8333-4689-8598-aa14338a255c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.42s/it]\n"
     ]
    }
   ],
   "source": [
    "audio_paths = glob('./audio_raw/*')\n",
    "for audio_path in tqdm(audio_paths):\n",
    "    audio_name = audio_path.split('/')[-1]\n",
    "    audio_name_no_ext = audio_name.split('.')[0]\n",
    "    output_path = f'./wav_raw/{audio_name_no_ext}.wav'\n",
    "    ffmpeg_script = f'ffmpeg -i {audio_path} -vn -acodec pcm_s16le -ar 44100 -ac 2 {output_path} -y'\n",
    "    ffmpeg_output = subprocess.run(\n",
    "        ffmpeg_script, \n",
    "        shell=True, \n",
    "        check=True, \n",
    "        capture_output=True,\n",
    "        text=True)\n",
    "    logger.info(ffmpeg_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3f71b622-5691-4184-b568-f430c5fe2c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 4/4 [00:01<00:00,  2.03it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_wav_duration(file_path):\n",
    "    with wave.open(file_path, 'rb') as wav_file:\n",
    "        num_frames = wav_file.getnframes()\n",
    "        frame_rate = wav_file.getframerate()\n",
    "        duration = num_frames / float(frame_rate)\n",
    "        return duration\n",
    "\n",
    "\n",
    "wav_paths = glob('./wav_raw/*.wav')\n",
    "for wav_path in tqdm(wav_paths):\n",
    "    duration = get_wav_duration(wav_path)\n",
    "    wav_name = wav_path.split('/')[-1]\n",
    "    wav_name_no_ext = wav_name.split('.')[0]\n",
    "    if duration > 600:\n",
    "        segment_wav_path = f'./wav_10_minutes/{wav_name_no_ext}_%06d.wav'\n",
    "        ffmpeg_script = f'ffmpeg -i {wav_path} -f segment -segment_time 600 -c copy {segment_wav_path}'\n",
    "        ffmpeg_output = subprocess.run(\n",
    "            ffmpeg_script, \n",
    "            shell=True, \n",
    "            check=True, \n",
    "            capture_output=True,\n",
    "            text=True)\n",
    "        logger.info(ffmpeg_output)\n",
    "    else:\n",
    "        shutil.copy(wav_path, f'./wav_10_minutes/{wav_name_no_ext}.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c6c49e52-bf2e-4f7c-867c-697d79f7cf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diarize_and_remove_overlap(segmented_wav_path):\n",
    "    diarization = pipeline(segmented_wav_path)\n",
    "    start_end_speakers_list = []\n",
    "    for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "        start_end = [turn.start, turn.end]\n",
    "        start_end_speakers_list.append([start_end, speaker])\n",
    "    start_end_speakers_list = sorted(start_end_speakers_list, key=lambda sublist: sublist[0][0])\n",
    "    start_end_speakers_list_no_overlap = []\n",
    "    compared_sublist = start_end_speakers_list[0]\n",
    "    for index in range(1, len(start_end_speakers_list)):\n",
    "        current_sublist = start_end_speakers_list[index]\n",
    "        if compared_sublist[0][1] > current_sublist[0][0]:\n",
    "            continue\n",
    "        start_end_speakers_list_no_overlap.append(current_sublist)\n",
    "        compared_sublist = current_sublist\n",
    "    logger.info(\n",
    "        f'Original diarized segments: {len(start_end_speakers_list)}'\n",
    "        f'Overlap removed: {len(start_end_speakers_list_no_overlap)}'\n",
    "    )\n",
    "    logger.info(f'Lost {1 - len(start_end_speakers_list_no_overlap) / (len(start_end_speakers_list)):.2f}%')\n",
    "    speaker_dict = {segmented_wav_path: {}}\n",
    "    for start_end, speaker in start_end_speakers_list_no_overlap:\n",
    "        if speaker not in speaker_dict[segmented_wav_path]:\n",
    "            speaker_dict[segmented_wav_path][speaker] = []\n",
    "        speaker_dict[segmented_wav_path][speaker].append(start_end)\n",
    "    return speaker_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d87d7df0-f136-4efc-9a56-22eb4fe6c20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 2/2 [00:44<00:00, 22.42s/it]\n"
     ]
    }
   ],
   "source": [
    "speaker_dict_list = []\n",
    "segmented_wav_paths = glob('./wav_10_minutes/*.wav')\n",
    "for segmented_wav_path in tqdm(segmented_wav_paths):\n",
    "    segmented_wav_name = segmented_wav_path.split('/')[-1]\n",
    "    segmented_wav_name_no_ext = segmented_wav_name.split('.')[0]\n",
    "    temp_speaker_dict = diarize_and_remove_overlap(segmented_wav_path)\n",
    "    speaker_dict_list.append(temp_speaker_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "37d9c96e-455a-40d2-8df3-cc930aa95cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 35.44it/s]\n"
     ]
    }
   ],
   "source": [
    "for speaker_dict in tqdm(speaker_dict_list):\n",
    "    segmented_wav_name = list(speaker_dict.keys())[0].split('/')[-1]\n",
    "    segmented_wav_name_no_ext = segmented_wav_name.split('.')[0]\n",
    "    diarized_sub_dir_path = f'./diarized_results/{segmented_wav_name_no_ext}'\n",
    "    if not os.path.exists(diarized_sub_dir_path):\n",
    "        os.mkdir(diarized_sub_dir_path)\n",
    "    wav_source = AudioSegment.from_wav(list(speaker_dict.keys())[0])\n",
    "    for speaker in speaker_dict[list(speaker_dict.keys())[0]]:\n",
    "        speaker_path = f'{diarized_sub_dir_path}/{speaker}'\n",
    "        if not os.path.exists(speaker_path):\n",
    "            os.mkdir(speaker_path)\n",
    "        for index, start_end in enumerate(speaker_dict[list(speaker_dict.keys())[0]][speaker]):\n",
    "            t1 = start_end[0] * 1000\n",
    "            t2 = start_end[1] * 1000\n",
    "            wav_snippet = wav_source[t1: t2]\n",
    "            wav_snippet_path = f'{speaker_path}/{index}.wav'\n",
    "            wav_snippet.export(wav_snippet_path, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2c5bb755-5ce1-4d4f-8fd6-50a5ad92d2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all files with less than 3 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2fde0d9a-36cd-4891-95b9-a88a5e8ee2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove noise from main speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a7de7109-2804-49d7-954e-ab9dff90c453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check required properties to send to trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24a476d-9194-4458-99a1-54e4183c233d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a3965c6f-dd7f-4802-8e56-00eceb6dddc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
